import scrapyfrom pymongo import MongoClientfrom datetime import datetimeMONTH = {	"January": "01",	"February": "02",	"March": "03",	"April": "04",	"May": "05",	"June": "06",	"July": "07",	"August": "08",	"September": "09",	"October": "10",	"November": "11",	"December": "12"}client = MongoClient('localhost', 27017, connect=False)db_articles = client['articles']collection = db_articles['ppf']class NewsArchiveScrapper(scrapy.Spider):	name = "news_archive2"	start_urls = ['https://www.pakistanpressfoundation.org']	def parse(self, response):		link = "https://www.pakistanpressfoundation.org/category/news-archives/page/{}"		#categories = ['front-page', 'back-page', 'national', 'business', 'international', 'sport']		for page in range(1, 1402):			if page == 1:				parsed_link = "https://www.pakistanpressfoundation.org/category/news-archives"			else:				parsed_link = link.format(page)			request = scrapy.Request(parsed_link, callback=self.parse_page)			yield request			break		def parse_page(self, response):		data = []		SET_SELECTOR = '.post_list'		for res in response.css(SET_SELECTOR):			data.append(res.css('.post_title a ::attr(href)').extract_first())		print("<><><><><>LENGTH: ", len(data))		for link in data:			#print(">>>>>>LINK: ", link)			request = scrapy.Request(					url=link,					callback=self.parse_article				 )			yield request					#print("I came template__header")	def parse_article(self, response):		#print('>>>>>>RES: ', response)		SET_SELECTOR = '.post_list'		articles = []		header = response.css(SET_SELECTOR)[0]		# category = header.css('.category a ::text').extract_first()		# category = 'General News' if category == 'News Archives' else category		# d = header.css('.date ::text').extract_first()		# date_string = "-".join([		# 		MONTH[d.split(',')[0].split(' ')[0]],		# 		d.split(',')[0].split(' ')[1],		# 		d.split(',')[-1]		# 	])		# date_format = "%m-%d-%Y"		# date = int(datetime.strptime(date_string.replace(" ",""), date_format).timestamp())		title = header.css('.post_title ::text').extract_first()		img_src = header.css(".post_content a img::attr(src)").extract_first()		# article = {		# 	'title': title.replace("\n", ""),		# 	'date': date,		# 	'category': category,		# 	'indexed': False,		# 	'img_src': img_src		# }				#print("title ::", article['title'])		# content = response.css('.post_content')		# divs = response.xpath('//div')		# article['content'] = ' '.join(content.css('.post_content p ::text').extract())		collection.update_one({'title':title}, {'$set': {'image_src': img_src}}, upsert=True)		#print('/n/n---------------------------------')		#print(article)		#print('/n/n---------------------------------')